{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BPvqlgECqZ2v"
      },
      "outputs": [],
      "source": [
        "\n",
        "#########################################################################\n",
        "#                                                                       #\n",
        "#               <<  FUNCTIONS IN THIS FILE      >>                      #\n",
        "#                                                                       #\n",
        "# Short print: p()                                                      #\n",
        "# Load CSV: load_csv()                                                  #\n",
        "# Plot data: plot_data()                                                #\n",
        "# Correlation Matrix: corr_matrix()                                     #\n",
        "# Top correlated pairs: top_pairs()                                     #\n",
        "# Random forest model: random_forest()                                  #\n",
        "# Prediction vs Observation: pred_obs()                                 #\n",
        "# Interaction term: interaction()                                       #\n",
        "#                                                                       #\n",
        "########################################################################\n",
        "\n",
        "\n",
        "###############################################################################\n",
        "\n",
        "# import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import ppscore as pps\n",
        "from sklearn.ensemble import RandomForestRegressor as RFR\n",
        "from sklearn.ensemble import RandomForestClassifier as RFC\n",
        "from sklearn.metrics import mean_absolute_error as MAE\n",
        "from sklearn.preprocessing import LabelEncoder as LE\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')\n",
        "\n",
        "###############################################################################s\n",
        "\n",
        "# Short print function\n",
        "def p(*args):\n",
        "    s = ''\n",
        "    for a in args:\n",
        "        s += str(a) + ' '\n",
        "    print(s)\n",
        "\n",
        "\n",
        "# Load CSV files\n",
        "def load_csv(filename):\n",
        "    try:\n",
        "        df = pd.read_csv(filename, delimiter=',')\n",
        "        print('Cargado con éxito (', filename, ')')\n",
        "        return df\n",
        "    except Exception as ex:\n",
        "        print(ex)\n",
        "        print('No se pudo cargar el archivo!')\n",
        "\n",
        "\n",
        "# Plot data with a better resolution\n",
        "# inputs are: x, y, pltype, fig size, legend, title, xlabel, ylabel, color of plot, trend_line, regresion degree*, color of reg line*\n",
        "# * values are optional (if trend_line is True)\n",
        "# current accepted plot types: 'linear' plot, 'scatter' plot, 'dashed' plot, 'bar' plot\n",
        "def plot_data(*args):\n",
        "    # unpack arguments\n",
        "    try:\n",
        "        x = args[0]\n",
        "        y = args[1]\n",
        "        pltype = args[2]\n",
        "        size = args[3]\n",
        "        leg = args[4]\n",
        "        title = args[5]\n",
        "        xlabel = args[6]\n",
        "        ylabel = args[7]\n",
        "        color_plot = args[8]\n",
        "        trend_line = args[9]\n",
        "    except Exception as ex:\n",
        "        print('Número incorrecto de inputs')\n",
        "\n",
        "    if trend_line == True:\n",
        "        try:\n",
        "            reg_degree = args[10]\n",
        "        except:\n",
        "            reg_degree = 1 # default\n",
        "        try:\n",
        "            reg_color = args[11]\n",
        "        except:\n",
        "            reg_color = 'purple'\n",
        "\n",
        "    # plot settings\n",
        "    fig, ax = plt.subplots(1)\n",
        "    fig.set_figwidth(size[0])\n",
        "    fig.set_figheight(size[1])\n",
        "\n",
        "    # select plot type\n",
        "    if pltype == 'scatter':\n",
        "        plt.scatter(x, y, label=leg, color=color_plot)\n",
        "    elif pltype == 'line':\n",
        "        plt.plot(x, y, label=leg, linestyle='-', color=color_plot)\n",
        "    elif pltype == 'dashed':\n",
        "        plt.plot(x, y, label=leg, linestyle='--', color=color_plot)\n",
        "    elif pltype == 'bar':\n",
        "        plt.bar(x, y, label=leg, color=color_plot)\n",
        "\n",
        "    # trend line\n",
        "    if trend_line == True:\n",
        "        z = np.poly1d(np.polyfit(x, y, deg=reg_degree))\n",
        "        plt.plot(x, z(x), linestyle='-.', color=reg_color)\n",
        "\n",
        "    # plot display\n",
        "    plt.xlabel(xlabel, fontsize=16)\n",
        "    plt.ylabel(ylabel, fontsize=16)\n",
        "    if leg != '':\n",
        "        plt.legend(fontsize=16)\n",
        "    plt.title(title, fontsize=24)\n",
        "\n",
        "    # tick size\n",
        "    if pltype == 'scatter' or pltype == 'line':\n",
        "        for tick in ax.xaxis.get_major_ticks():\n",
        "            tick.label.set_fontsize(14)\n",
        "        for tick in ax.yaxis.get_major_ticks():\n",
        "            tick.label.set_fontsize(14)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "# Correlation Matrix\n",
        "# name is type of correlation: 'pearson', 'spearman', 'ppscore'\n",
        "def corr_matrix(df, name):\n",
        "    if name == 'pearson':\n",
        "        corrp = df.corr(method='pearson')\n",
        "        sns.heatmap(corrp, vmin=0, vmax=1, cmap=\"Blues\", linewidths=0.5, annot=True)\n",
        "    elif name == 'spearman':\n",
        "        corrs = df.corr(method='spearman')\n",
        "        sns.heatmap(corrs, vmin=0, vmax=1, cmap=\"Blues\", linewidths=0.5, annot=True)\n",
        "    elif name ==  'ppscore':\n",
        "        ppscore = pps.matrix(df)\n",
        "        sns.heatmap(ppscore[['x', 'y', 'ppscore']].pivot(columns='x', index='y', values='ppscore'),\n",
        "                vmin=0, vmax=1, cmap=\"Blues\", linewidths=0.5, annot=True)\n",
        "\n",
        "\n",
        "# Get top correlated pairs\n",
        "# name is the type of correlation: 'pearson', 'spearman', 'ppscore'\n",
        "# n is how many correlated pairs should be shown\n",
        "def top_pairs(df, name, n):\n",
        "    if name == 'pearson' or name == 'spearman':\n",
        "        corr_matrix = df.corr(method=name)\n",
        "        cols = df.columns\n",
        "        to_drop = set()\n",
        "        for i in range(df.shape[1]):\n",
        "            for j in range(i+1):\n",
        "                to_drop.add((cols[i], cols[j]))\n",
        "        corr_pairs = corr_matrix.abs().unstack()\n",
        "        corr_pairs = corr_pairs.drop(labels=to_drop).sort_values(ascending=False)\n",
        "        print(corr_pairs[:n])\n",
        "    elif name == 'ppscore':\n",
        "        ppscore = pps.matrix(df)\n",
        "        corr_matrix = ppscore[['x', 'y', 'ppscore']]\n",
        "        print(corr_matrix.sort_values(by='ppscore', ascending=False).reset_index().drop('index', axis=1)\n",
        "          .drop(index=[i for i in range(len(df.columns))])[:n].reset_index().drop('index', axis=1))\n",
        "\n",
        "\n",
        "# Random Forest Model\n",
        "# Regression -> choose True, Classification -> Choose False\n",
        "# target is the target to predict\n",
        "# n_est is the number of estimators (can be a list or an integer)\n",
        "# m_dep is the depth of the tree (can be a list or an integer)\n",
        "# split is the split between training and validation data (between 0.01 and 0.99)\n",
        "def random_forest(df, regression, target, n_est, m_dep, split, *criteria):\n",
        "    # categorical encoding\n",
        "    cols = df.dtypes\n",
        "    hot_cols, label_cols, num_cols = [], [], []\n",
        "    for i in range(len(cols)):\n",
        "        if cols[i] == 'object':\n",
        "            if len(df[cols.index[i]].unique()) < 20:\n",
        "                hot_cols.append(cols.index[i])\n",
        "            else:\n",
        "                label_cols.append(cols.index[i])\n",
        "        else:\n",
        "            num_cols.append(cols.index[i])\n",
        "\n",
        "    # label encoding\n",
        "    label_encoder = LE\n",
        "    for l in label_cols:\n",
        "        df[l] = label_encoder.fit_transform(df[l], df[target])\n",
        "\n",
        "    # one hot encoding\n",
        "    df = pd.get_dummies(df, columns=hot_cols, prefix='enc_')\n",
        "\n",
        "    # drop empty rows\n",
        "    df.dropna(inplace=True)\n",
        "\n",
        "    # data splitting\n",
        "    split = round(df.shape[0]*(split))\n",
        "    x_cols = list(df.columns)\n",
        "    x_cols.remove(target)\n",
        "\n",
        "    # training and validation sets\n",
        "    train_X = df[x_cols][:split]\n",
        "    train_y = df[target][:split]\n",
        "    test_X = df[x_cols][split+1:]\n",
        "    test_y = df[target][split+1:]\n",
        "\n",
        "    # check for single values\n",
        "    if type(n_est) != list:\n",
        "        n_est = [n_est]\n",
        "    if type(m_dep) != list:\n",
        "        m_dep = [m_dep]\n",
        "\n",
        "    # training criterion\n",
        "    flag = False\n",
        "    reg_criteria = {'mse', 'mae'}\n",
        "    cla_criteria = {'gini', 'entropy'}\n",
        "    if type(criteria) != 'str':\n",
        "        criteria = str(criteria[0])\n",
        "    if criteria != None:\n",
        "        if regression == True:\n",
        "            p('1', criteria in reg_criteria)\n",
        "            if criteria in reg_criteria:\n",
        "                p('2')\n",
        "                flag = True\n",
        "        else:\n",
        "            p('3')\n",
        "            if criteria in cla_criteria:\n",
        "                p('4')\n",
        "                flag = True\n",
        "\n",
        "    # model training\n",
        "    if flag == True:\n",
        "        best_mae = 99999\n",
        "        best_model = 0\n",
        "        best_pair = [0,0]\n",
        "        if regression == True:\n",
        "            for n in tqdm(n_est):\n",
        "                for m in m_dep:\n",
        "                    model = RFR(n_estimators=n, max_depth=m, criterion='mae')\n",
        "                    model.fit(train_X, train_y)\n",
        "                    predict_y = model.predict(test_X)\n",
        "                    mae = MAE(test_y, predict_y)\n",
        "                    if mae < best_mae:\n",
        "                        best_model = model\n",
        "                        best_mae = mae\n",
        "                        best_pair = [n, m]\n",
        "        else:\n",
        "            for n in tqdm(n_est):\n",
        "                for m in m_dep:\n",
        "                    model = RFC(n_estimators=n, max_depth=m, criterion='entropy')\n",
        "                    model.fit(train_X, train_y)\n",
        "                    predict_y = model.predict(test_X)\n",
        "                    mae = MAE(test_y, predict_y)\n",
        "                    if mae < best_mae:\n",
        "                        best_model = model\n",
        "                        best_mae = mae\n",
        "                        best_pair = [n, m]\n",
        "\n",
        "\n",
        "        # model results\n",
        "        print('No. of estimators: ', best_pair[0], ' | Max depth of tree: ', best_pair[1])\n",
        "        print('MAE: ' , best_mae)\n",
        "\n",
        "        return best_model\n",
        "\n",
        "    else:\n",
        "        print('Inadequate criteria for chosen model')\n",
        "        print('Regression: mse,mae  |  Classifier: gini,entropy')\n",
        "\n",
        "\n",
        "# Compare model prediction with observed value\n",
        "def pred_obs(model, df, target, row):\n",
        "    # get relevant rows\n",
        "    l = list(df.columns)\n",
        "    l.remove(target)\n",
        "    j = row\n",
        "\n",
        "    x_obs = df[l].reset_index().drop('index',axis=1).iloc[j:j+1],\n",
        "    y_obs = df[target].iloc[j:j+1]\n",
        "\n",
        "    y_pred = model.predict(x_obs)\n",
        "    y_obs = y_obs.values[0]\n",
        "\n",
        "    while type(y_pred) == np.ndarray:\n",
        "        y_pred = y_pred[0]\n",
        "\n",
        "    print('Prediction: ', y_pred, ' | Observed: ', y_obs, ' | Difference: ', abs(y_pred - y_obs))\n",
        "    print('Percent Error  (%): ', round((y_pred - y_obs)/y_obs*100,2))\n",
        "\n",
        "\n",
        "# Add interaction terms\n",
        "# termlist is the list of columns names to include\n",
        "# agg is the interaction type: 'sum', 'sub', 'mul', 'div'\n",
        "# name is the name of the new interaction column\n",
        "def interaction(df, termlist, agg, name):\n",
        "    if agg == 'sum':\n",
        "        try:\n",
        "            interactions = 0\n",
        "            for term in termlist:\n",
        "                interactions += df[term]\n",
        "            df[name] = interactions\n",
        "        except:\n",
        "            print('No se pueden combinar los términos')\n",
        "    if agg == 'sub':\n",
        "        try:\n",
        "            interactions = 0\n",
        "            interactions += df[termlist[0]]\n",
        "            for term in termlist[1:]:\n",
        "                interactions -= df[term]\n",
        "            df[name] = interactions\n",
        "        except:\n",
        "            print('No se pueden combinar los términos')\n",
        "    if agg == 'mul':\n",
        "        try:\n",
        "            interactions = 1\n",
        "            for term in termlist:\n",
        "                interactions *= df[term]\n",
        "            df[name] = interactions\n",
        "        except:\n",
        "            print('No se pueden combinar los términos.')\n",
        "    if agg == 'div':\n",
        "        try:\n",
        "            interactions = 0\n",
        "            interactions += df[termlist[0]]\n",
        "            for term in termlist[1:]:\n",
        "                interactions /= df[term]\n",
        "            df[name] = interactions\n",
        "        except:\n",
        "            print('No se pueden combinar los términos.')\n",
        "\n",
        "    return df"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}